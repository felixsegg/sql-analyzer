<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Generation Help</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<b>Generation Help</b><br><br>
This window runs batch generation of SQL queries for the LLMs and prompts configured in <i>Generation Settings</i>.
<ul>
    <li>
        <b>Settings (⚙):</b><br>
        Open the Generation Settings dialog to choose LLMs, prompts, repetitions, and thread pool size.
    </li>
    <li>
        <b>Start:</b><br>
        Starts the batch job. Each LLM shows a dual progress bar:<br>
        – <b>Gray</b> = calls started (submitted).<br>
        – <b>Red</b> = calls finished (completed and recorded).<br>
        Both reach 100% when done.
    </li>
    <li>
        <b>Rate limits:</b><br>
        If a provider’s rate limit is hit, a countdown appears indicating the next retry time. Retries happen automatically.
        <br>While the timer runs, progress may still advance (in-flight calls can complete and some new calls may start if allowed). This is expected.
    </li>
    <li>
        <b>Cancel:</b><br>
        Stops the ongoing job and clears progress indicators.
    </li>
    <li>
        <b>Save:</b><br>
        Enabled after completion. Saves all generated queries and opens the “Generated queries” overview filtered to the new results.
    </li>
</ul>
Notes:
<ul>
    <li>Multiple repetitions per Prompt–LLM pair are used to avoid cached responses by varying temperature across calls (not to test creativity).</li>
    <li>Very large thread pools can trigger rate limits; very small pools slow execution.</li>
    <li>Ensure LLM entries (API, model, key) are set; dummy providers don’t require keys.</li>
</ul>
</body>
</html>
